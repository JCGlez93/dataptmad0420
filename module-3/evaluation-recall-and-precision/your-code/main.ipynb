{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "first_image = mnist.test.images[3600]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05882353, 0.09803922, 0.32156864, 0.5647059 , 0.86666673,\n",
       "       0.9960785 , 0.9607844 , 0.25490198, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09411766, 0.47058827, 0.8235295 , 0.9176471 ,\n",
       "       0.9921569 , 0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.6627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.4156863 , 0.8235295 , 0.882353  ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9960785 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.34509805, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34509805,\n",
       "       0.98823535, 0.9921569 , 0.9921569 , 0.98823535, 0.9058824 ,\n",
       "       0.58431375, 0.50980395, 0.9960785 , 0.9921569 , 0.9921569 ,\n",
       "       0.8705883 , 0.01568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5176471 , 0.43921572,\n",
       "       0.43921572, 0.32941177, 0.        , 0.06666667, 0.74509805,\n",
       "       0.9960785 , 0.9921569 , 0.9921569 , 0.19215688, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.30588236, 0.9921569 , 0.9960785 , 0.9921569 ,\n",
       "       0.6862745 , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00784314, 0.52156866,\n",
       "       0.9921569 , 0.9960785 , 0.9803922 , 0.38823533, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.4431373 , 0.9921569 , 0.9921569 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568628, 0.7254902 ,\n",
       "       0.9921569 , 0.9921569 , 0.90196085, 0.07843138, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.23529413, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.4901961 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04705883, 0.92549026,\n",
       "       0.9960785 , 0.9960785 , 0.94117653, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.46274513, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.44705886, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.9568628 ,\n",
       "       0.9921569 , 0.9921569 , 0.7411765 , 0.02352941, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25882354, 0.9921569 , 0.9921569 , 0.9803922 ,\n",
       "       0.4431373 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.15294118, 0.8745099 ,\n",
       "       0.9921569 , 0.9921569 , 0.7254902 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10588236, 0.18039216, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.67058825, 0.9921569 , 0.9921569 , 0.8078432 ,\n",
       "       0.08627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.18431373, 0.4431373 , 0.7803922 , 0.882353  ,\n",
       "       0.8196079 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5647059 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.16078432, 0.04705883, 0.1764706 ,\n",
       "       0.10196079, 0.48235297, 0.4784314 , 0.8352942 , 0.95294124,\n",
       "       0.9921569 , 0.9803922 , 0.7411765 , 0.2392157 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8235295 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 1.        ,\n",
       "       0.9921569 , 0.9921569 , 0.9803922 , 0.8196079 , 0.34509805,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.57254905,\n",
       "       0.9803922 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9960785 , 0.9921569 , 0.7411765 ,\n",
       "       0.25490198, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16078432, 0.56078434,\n",
       "       0.7490196 , 0.7490196 , 0.56078434, 0.56078434, 0.56078434,\n",
       "       0.12941177, 0.12941177, 0.02352941, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "train_size = (60000/70000)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
